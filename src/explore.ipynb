{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "total_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv\")\n",
                "total_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2999 entries, 0 to 2998\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column   Non-Null Count  Dtype \n",
                        "---  ------   --------------  ----- \n",
                        " 0   url      2999 non-null   object\n",
                        " 1   is_spam  2999 non-null   bool  \n",
                        "dtypes: bool(1), object(1)\n",
                        "memory usage: 26.5+ KB\n"
                    ]
                }
            ],
            "source": [
                "total_data.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "630\n"
                    ]
                }
            ],
            "source": [
                "duplicates = total_data.duplicated().sum()\n",
                "print(duplicates)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape de los Datos (2369, 2)\n",
                        "Spam: 244\n",
                        "No spam: 2125\n"
                    ]
                }
            ],
            "source": [
                "total_data2 = total_data.drop_duplicates()\n",
                "total_data2 = total_data2.reset_index(inplace = False, drop = True)\n",
                "print(\"Shape de los Datos\", total_data2.shape)\n",
                "print(f\"Spam: {len(total_data2.loc[total_data2.is_spam == 1])}\")\n",
                "print(f\"No spam: {len(total_data2.loc[total_data2.is_spam == 0])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(2369, 2)\n",
                        "Spam: 244\n",
                        "No spam: 2125\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "\n",
                "\n",
                "def preprocess_url(url):\n",
                "    # Convertir a minúsculas\n",
                "    url = url.lower()\n",
                "\n",
                "    # Eliminar todos los signos de puntuación y los términos comunes\n",
                "    url = re.sub(r'[^\\w\\s]|www|https?|http|com', '', url)\n",
                "\n",
                "    url = re.sub(r'\\d+', '', url)\n",
                "\n",
                "    # Dividir la URL en partes\n",
                " # Encontrar y seleccionar solo palabras completas\n",
                "    words = re.findall(r'\\b[a-zA-Z]+\\b', url)\n",
                "\n",
                "    # Formatear las palabras entre corchetes []\n",
                "    url_processed = \"[\" + \",\".join(words) + \"]\"\n",
                "\n",
                "    return url_processed\n",
                "\n",
                "# Aplicar el preprocesamiento a la columna \"URL\" del DataFrame\n",
                "df[\"url\"] = df[\"url\"].apply(preprocess_url)\n",
                "\n",
                "# Mostrar las primeras filas del DataFrame para verificar el resultado\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "from collections import Counter\n",
                "from wordcloud import WordCloud\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Función para extraer tokens de una URL procesada\n",
                "def extract_tokens(url):\n",
                "    # Remover corchetes y comas\n",
                "    url = re.sub(r'[\\[\\],]', '', url)\n",
                "    \n",
                "    # Dividir la URL procesada en tokens (palabras)\n",
                "    tokens = url.split()\n",
                "    \n",
                "    return tokens\n",
                "\n",
                "tokens_list = df[\"url\"].apply(extract_tokens)\n",
                "\n",
                "all_tokens = [token for tokens in tokens_list for token in tokens]\n",
                "\n",
                "token_freq = Counter(all_tokens)\n",
                "\n",
                "# Crear la wordcloud a partir de los tokens y sus frecuencias\n",
                "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(token_freq)\n",
                "\n",
                "# Mostrar la wordcloud\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.imshow(wordcloud, interpolation='bilinear')\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# Convertir la lista de tokens en una lista de strings\n",
                "tokens_list_str = [\" \".join(tokens) for tokens in tokens_list]\n",
                "\n",
                "# Crear un objeto TfidfVectorizer\n",
                "vectorizer = TfidfVectorizer(max_features=5000, max_df=0.8, min_df=5)\n",
                "\n",
                "# Aplicar TfidfVectorizer a la lista de tokens\n",
                "X = vectorizer.fit_transform(tokens_list_str).toarray()\n",
                "\n",
                "y = df[\"is_spam\"]\n",
                "\n",
                "# Mostrar las primeras 5 filas de la matriz X\n",
                "X[:5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "# Define los hiperparámetros a ajustar\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10, 100],                    # Parámetro de regularización\n",
                "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Tipo de kernel\n",
                "    'gamma': ['scale', 'auto'],                # Coeficiente del kernel\n",
                "    'class_weight': [None, 'balanced'],        # Peso de las clases\n",
                "    'probability': [True, False],               # Habilitar predicción de probabilidades\n",
                "    'shrinking': [True, False],                 # Reducción de vectores de soporte\n",
                "}\n",
                "\n",
                "# Instancia el modelo SVC\n",
                "svm_model = SVC()\n",
                "\n",
                "# Realiza la búsqueda de hiperparámetros utilizando GridSearchCV\n",
                "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
                "\n",
                "# Ajusta el modelo a los datos\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "# Muestra los mejores hiperparámetros encontrados\n",
                "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
                "\n",
                "# Muestra la mejor puntuación obtenida\n",
                "print(\"Mejor puntuación:\", grid_search.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = grid_search.best_estimator_.predict(X_test)\n",
                "y_pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "accuracy_score(y_test, y_pred)*100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "# Calcula las métricas de evaluación\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred, average='weighted')  # o 'micro', 'macro', 'weighted'\n",
                "recall = recall_score(y_test, y_pred, average='weighted')  # o 'micro', 'macro', 'weighted'\n",
                "f1 = f1_score(y_test, y_pred, average='weighted')  # o 'micro', 'macro', 'weighted'\n",
                "\n",
                "# Imprime las métricas\n",
                "print(\"Accuracy:\", accuracy*100)\n",
                "print(\"Precision:\", precision*100)\n",
                "print(\"Recall:\", recall*100)\n",
                "print(\"F1 Score:\", f1*100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.svm import SVC\n",
                "from sklearn.datasets import load_iris\n",
                "import joblib\n",
                "\n",
                "# Entrenar un modelo SVM de ejemplo (puedes reemplazar esto con tu propio modelo)\n",
                "X, y = load_iris(return_X_y=True)\n",
                "model = SVC(kernel='linear')\n",
                "model.fit(X, y)\n",
                "\n",
                "# Guardar el modelo en un archivo\n",
                "joblib.dump(model, 'modelo_svm.pkl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (venv-npl)",
            "language": "python",
            "name": "venv-npl"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
